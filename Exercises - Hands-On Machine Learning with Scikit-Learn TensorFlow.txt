Chapter 1. The Machine Learning Landscape
1. How would you define Machine Learning?
2. Can you name four types of problems where it shines?
3. What is a labeled training set?
4. What are the two most common supervised tasks?
5. Can you name four common unsupervised tasks?
6. What type of Machine Learning algorithm would you use to allow a robot to walk in various unknown terrains?
7. What type of algorithm would you use to segment your customers into multiple groups?
8. Would you frame the problem of spam detection as a supervised learning problem or an unsupervised learning problem?
9. What is an online learning system?
10. What is out-of-core learning?
11. What type of learning algorithm relies on a similarity measure to make predictions?
12. What is the difference between a model parameter and a learning algorithm’s hyperparameter?
13. What do model-based learning algorithms search for? What is the most common strategy they use to succeed? How do they make predictions?
14. Can you name four of the main challenges in Machine Learning?
15. If your model performs great on the training data but generalizes poorly to new instances, what is happening? Can you name three possible solutions?
16. What is a test set and why would you want to use it?
17. What is the purpose of a validation set?
18. What can go wrong if you tune hyperparameters using the test set?
19. What is cross-validation and why would you prefer it to a validation set?




Chapter 2. End-to-End Machine Learning Project
In this chapter, you will go through an example project end to end, pretending to be a recently hired data scientist in a real estate company.1 Here are the main steps you will go through:
1. Look at the big picture.
2. Get the data.
3. Discover and visualize the data to gain insights.
4. Prepare the data for Machine Learning algorithms.
5. Select a model and train it.
6. Fine-tune your model.
7. Present your solution.
8. Launch, monitor, and maintain your system.




Chapter 3. Classification
1. Try to build a classifier for the MNIST dataset that achieves over 97% accuracy on the test set. Hint: the KNeighborsClassifier works quite well for this task; you just need to find good hyperparameter values (try a grid search on the weights and n_neighbors hyperparameters.
2. Write a function that can shift an MNIST image in any direction (left, right, up, or down) by one pixel. Hint: You can use the shift() function from the scipy.ndimage.interpolation module. For example, shift(image, [2,1], cval=0) shifts the image 2 pixels down and 1 pixel to the right. Then, for each image in the training set, create four shifted copies (one per direction) and add them to the training set. Finally, train your best model on this expanded training set and measure its accuracy on the test set. You should observe that your model performs even better now. This technique of artificially growing the dataset is referred to as dataset augmentation or training set expansion.
3. Tackle the Titanic dataset from Kaggle.
4. Build a spam classifier:
   * Download examples from Apache SpamAssassin dataset
   * Unzip and familiarize yourself with the dataset
   * Split the datasets into training and test set
   * Write a data preparation pipeline to convert each email into a feature vector. Your pipeline should transform an email into a (sparse) vector indicating the presence or absence of each possible word. For example, if all emails only ever contain the words ('Hello', 'how', 'are', 'you') then the email 'Hello you Hello Hello you' would be converted to the vector [1,0,0,1] indicating the words that are present. Alternatively, [3,0,0,2] is also acceptable and represents a count of word occurrences in the sentence.
   * You may want to add hyperparameters to your preparation pipeline to control whether or not the to strip off email headers, convert each email to lowercase, remove punctuation, replace all URLs with 'URL', replace all numbers with 'NUMBER', or even perform stemming (there are python libraries you can utilize for this exercise).
   * Try out several classifiers and see if you can build a spam classifier with both high recall and high precision.






Chapter 4. Training Models
1. What Linear Regression training algorithm can you use if you have a training set with millions of features?
2. Suppose the features in your training set have very different scales. What algorithms might suffer from this, and how? What can you do about it?
3. Can Gradient Descent get stuck in a local minimum when training a Logistic Regression model?
4. Do all Gradient Descent algorithms lead to the same model provided you let them run long enough?
5. Suppose you use Batch Gradient Descent and you plot the validation error at every epoch. If you notice that the validation error consistently goes up, what is likely going on? How can you fix this?
6. Is it a good idea to stop Mini-batch Gradient Descent immediately when the validation error goes up?
7. Which Gradient Descent algorithm (among those we discussed) will reach the vicinity of the optimal solution the fastest? Which will actually converge? How can you make the others converge as well?
8. Suppose you are using Polynomial Regression. You plot the learning curves and you notice that there is a large gap between the training error and the validation error. What is happening? What are three ways to solve this?
9. Suppose you are using Ridge Regression and you notice that the training error and the validation error are almost equal and fairly high. Would you say that the model suffers from high bias or high variance? Should you increase the regularization hyperparameter α or reduce it?
10. Why would you want to use:
   * Ridge Regression instead of Linear Regression?
   * Lasso instead of Ridge Regression?
   * Elastic Net instead of Lasso?
1. Suppose you want to classify pictures as outdoor/indoor and daytime/nighttime. Should you implement two Logistic Regression classifiers or one Softmax Regression classifier?
2. Implement Batch Gradient Descent with early stopping for Softmax Regression (without using Scikit-Learn).







Chapter 5. Support Vector Machines
1. What is the fundamental idea behind SVMs?
2. What is a support vector?
3. Why is it important to scale the inputs when using SVM?
4. Can an SVM output a confidence score when it classifies an instance? What about a probability?
5. Should you use the primal or the dual form of the SVM problem to train a model on a training set with millions of instances and hundreds of features?
6. Say you trained  an SVM classifier with an RBF kernel. It seems to underfit the training set: should you increase or decrease γ (gamma)? What about C?
7. How should you set the QP parameters (H, f, A, b) to solve the soft margin linear SVM classifier problem using an off-the-shelf QP solver?
8. Train a LinearSVC on a linearly separable dataset. Then train an SVC and an SGDClassifier on the same dataset. See if you can get them to produce roughly the same model.
9. Train an SVM classifier on the MNIST dataset. Since the SVM classifiers are binary classifiers, you will need to use one-versus-all to classify all 10 digits. You may want to tune the hyperparameters using small validation sets to speed up the process. What accuracy can you reach?
10. Train an SVM regressor on the California housing dataset








Chapter 6. Decision Trees
1. what is the approximate depth of a Decision Tree (DT) trained without restriction on a training set with 1,000,000 instances?
2. Is a node's Gini impurity generally less than or greater than its parent's? Is generally this way or always this way?
3. If a Decision Tree is overfitting a dataset is it a good idea to try decreasing max_depth?
4. If a Decision Tree is underfitting a dataset is it a good idea to try scaling the input features?
5. If it takes one hour to train a DT on a training set containing 1 million instances, roughly how long will it take to train another DT on a dataset containing 10 million instances?
6. If the training set contains 100,000 instances will setting presort=True speed up training?
7. Train and fine-tune a DT for the moons dataset.
* Generate a moons dataset using make_moons(n_samples=10000, noise=0.4).
* Split it into a training set and a s test set using train_test_split().
* Use grid search with cross-validation (with the help of GridSearchCV class) to find good hyperparameter values for a DecisionTreeClassifier. Hint: try various values for max_leaf_nodes.
* Train it on the full training set using these hyperparameters and measure your model's performance on the test set. You should achieve roughly 85% to 87% accuracy.
1. Grow a forest.
* Continuing the previous exercise, generate 1000 subsets of the training set in which each contains 100 instances selected randomly. Hint: you can use Scikit-Learn's ShuffleSplit class for this.
* Train one DT on each subset using the best hyperparameters found above. Evaluate these 1000 DTs on the test set. Since they were trained on smaller sets they will likely perform worse than the first decision tree thus only achieving about 80% accuracy.
* Now comes the magic. For each test set instance generate the predictions of the 1000 DTs and keep only the most frequent prediction (use SciPy's mode() function for this) in order to obtain the majority-vote predictions over the test set.








Chapter 7. Ensemble Learning and Random Forests
1. Assume you have trained five different models on the exact same training data and they all achieve 95% precision. Is it possible to combine these models to get better results? If so, how? If not, why?
2. Explain the difference between hard and soft voting classifiers.
3. Is it possible to speed up training of a bagging ensemble by distributing it across multiple servers? What about pasting ensembles, boosting ensembles, random forest, or stacking ensembles?
4. What is the benefit of out-of-bag evaluation?
5. What makes Extra-Trees more random than regular Random Forests? How can this extra randomness help? Are Extra-Trees slower or faster than regular Random Forests?
6. What hyperparameters should you alter (and in what way and why) if your AdaBoost ensemble underfits the training data?
7. Should you increase or decrease the learning rate if your Gradient Boosting ensemble overfits the training set? Why? How do you do it?
8. Load the MNIST data (chapter 3) and split it into training, validation, and test sets (e.g. 40,000 training, 10,000 validation, 10,000 testing). Then train various classifiers (Random Forest, Extra-Trees, SVM, etc.). Next, try to combine them into an ensemble classifier that outperforms each individual classifier on the validation set using a hard or soft voting classifier. Once you have found one try it on the test set. How much better does it perform compared to the individual classifiers?
9. Runt the individual classifiers from the previous exercise to make predictions on the validation set, and create a new training set with the resulting predictions: each training instance is a vector containing the set of predictions from all your classifiers for an image, and the target is the image’s class. Congratulations, you have just trained a blender, and together with the classifiers they form a stacking ensemble! Now let’s evaluate the ensemble on the test set. For each image in the test set make predictions with all your classifiers and then feed the predictions to the blender to get the ensemble’s predictions. How does it compare to the voting classifier you trained earlier?








Chapter 8. Dimensionality Reduction
1. What are the main motivations when reducing a dataset’s dimensionality? Explain the advantages as well as any disadvantages. When should you use this technique and when should it be avoided (if ever)?
2. What is the curse of dimensionality?
3. Is it possible to reverse a reduction in a dataset’s dimensionality? If so, how? If not, why?
4. Can PCA be used to reduce the dimensionality of a highly nonlinear dataset?
5. Suppose you perform PCA on a 1,000-dimensional dataset, setting the explained variance ratio to 95%. How many dimensions will the resulting dataset have?
6. In what cases would you use vanilla PCA, Incremental PCA, Randomized PCA, or Kernel PCA?
7. How can you evaluate performance of a dimensionality reduction algorithm on your dataset?
8. Does it make any sense to chain two different dimensionality reduction algorithms?
9. Load the MNIST dataset (chapter 3) and split it into Train (60,000 instances) and Test (10,000 instances). Train a Random Forest classifier on the dataset and time ohow long it takes, then evaluate the resulting model on the test set. Next, use PCA to reduce the dataset’s dimensionality with an explained variance of 95%. Train a new Random Forest classifier on the reduced dataset and see how long it takes to complete. Was training faster? Why or why wouldn’t you expect it to be? How does a Random Forest classifier work? Finally, evaluate the classifier on the test set: how does it compare to the previous classifier?
10. Use t-SNE to reduce the MNIST dataset down to two dimensions and plot the result using Matplotlib. You can use a scatterplot with 10 different colors to represent each image’s target class. You could alternatively write colored digits at the location of each instance, or even plot scaled down versions of the digit images themselves (choose a subset of images as plotting all will quickly become cluttered). You should end up with a nice visualization with well separated clusters of digits. Try using other dimensionality reduction algorithms such as PCA, LLE, or MDS and compare the resulting visualizations.





Chapter 9. Up and Running with TensorFlow
1. What are the main benefits of creating a computation graph rather than directly executing the computations? What are the main drawbacks? Explain what a computation graph is with examples.
2. Is the statement a_val = a.eval(session=sess) equivalent to a_val = sess.run(a)? Explain what each does, highlighting similarities and differences between them.
3. Is the statement a_val, b_val = a.eval(session=sess), b.eval(session=sess) equivalent to a_val, b_val = sess.run([a,b])?
4. Can you run two graphs simultaneously?
5. If you create a graph g containing a variable w, then start two threads and open a session in each thread in which both are using graph g, will each session have its own copy of the variable w or will it be shared?
6. When is a variable initialized? When is it destroyed?
7. What is the difference between a placeholder and a variable?
8. What happens when you run the graph to evaluate an operation that depends on a placeholder but you don’t feed its value? What happens if the operation does not depend on the placeholder?
9. Can you feed the values of any operation when you run a graph, or just the value of the placeholders?
10. How can you set a variable to any value you want (during the execution phase)?
11. How many times does reverse-mode autodiff need to traverse the graph in order to compute the gradients of the cost function with regards to 10 variables? What about forward-mode autodiff? And symbolic differentiation? 
12. Implement Logistic Regression and Mini-batch Gradient Descent using TF. Train and evaluate a model on the moons dataset from chapter five and try adding all the bells and whistles:
* Define the graph within a logistic_regression() function that can easily be reused.
* Save checkpoints using a Saver at regular intervals during training and save the final model at the end of the training.
* Restore the last checkpoint upon startup if training was interrupted.
* Define the graph using nice scopes so the graph looks good in TensorBoard.
* Add summaries to visualize learning curves in TensorBoard.
* Tweak some hyperparameters such as the learning rate or the mini-batch size and look at the shape of the learning curve.


Chapter 10. Introduction to Artificial Neural Networks
In work




Chapter 11. Training Deep Neural Nets
In work




Chapter 12. Distributing TensorFlow Across Devices and Servers
In work


Chapter 13. Convolutional Neural Networks
In work




Chapter 14. Recurrent Neural Networks
In work




Chapter 15. Autoencoders
In work




Chapter 16. Reinforcement Learning
In work



